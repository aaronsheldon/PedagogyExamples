{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The $\\chi^2_\\Delta$ Test of Discrete Frequency Estimates\n",
    "\n",
    "The $\\chi^2_\\Delta$ Test, pronounced *\"Chi Square\"*, is used to compare the parameter\n",
    "estimates of two models of discrete frequency estimates from the same data, where the\n",
    "models' degrees of freedom differ by $\\Delta$, pronounce *\"Delta\"*. The degrees of freedom\n",
    "of a model is simply the number of independent parameters that uniquely identify a single\n",
    "model. In practice, this means we cannot use a parameterization where two different\n",
    "combinations of parameters yields the same model.\n",
    "\n",
    "> *For an example of a model that is **NOT** uniquely identifiable, consider an initial*\n",
    "> *model where we estimate the parameter $r_\\text{acc}$, the rate of traffic accidents per*\n",
    "> *year. We then refine this parameterization to $r_\\text{acc} = r_\\text{hr} \\times r_\\text{drv}$,*\n",
    "> *where $r_\\text{hr}$ is the parameter for the rate of accidents per driver-hour, and*\n",
    "> *$r_\\text{drv}$ is the parameter for the rate of driver-hours per year. In this*\n",
    "> *refinement there are many combinations of $r_\\text{hr}$ and $r_\\text{drv}$ that yield*\n",
    "> *the same value of $r_\\text{acc}$, and thus the refined parameterization is **NOT***\n",
    "> *uniquely identifiable.*\n",
    "\n",
    "To apply the $\\chi^2_\\Delta$ Test to estimates of discrete frequencies our two models must\n",
    "satisfy the following criteria:\n",
    "* The estimates of the models respective parameters must be based on the same observations\n",
    "of independent identically distributed samples. You cannot compare models derived from\n",
    "different observations.\n",
    "* The model with the fewer degrees of freedom must be a restricted version of the model\n",
    "with the larger degrees of freedom. That is there are additional relationships imposed on\n",
    "the parameters in the model with the fewer degrees of freedom, such as independence between\n",
    "variables in the observation.\n",
    "* For both models must use Maximum Likelihood Estimation to fit the parameters.\n",
    "* There are other regularity conditions around the theoretical finiteness of the means and\n",
    "variances of the parameter estimates, and bounds on tails of the models. However, for models\n",
    "of discrete frequency estimates these are generally satisfied.\n",
    "\n",
    "If these conditions are satisfied then the $\\chi^2_\\Delta$ Test gives the conditional\n",
    "asymptotic tail probability (one minus the cumulative probability) of observing as large of\n",
    "a difference between the frequency estimates of the two models, in the limit of large sample\n",
    "sizes, and assuming the model with the fewer degrees of freedom is true.\n",
    "\n",
    "It is the role of the Data Analyst to contextualize the observed probability by providing an\n",
    "interpretation within the context of the observed process. Improbably large differences\n",
    "between the estimated frequencies are conventionally interpreted to indicate that the model\n",
    "with fewer degrees of freedom is an inferior explanation, where as the model with the larger\n",
    "number of degrees of freedom is a superior explanation.\n",
    "\n",
    "The following concepts are related to the $\\chi^2_\\Delta$ Test:\n",
    "* The [Likelihood Ratio Test](https://en.wikipedia.org/wiki/Likelihood-ratio_test) of the\n",
    "[Maximum Likelihood Estimate](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation).\n",
    "* The [G-Test](https://en.wikipedia.org/wiki/G-test) of the G-Statistic.\n",
    "* [Wilks' Theorem](https://en.wikipedia.org/wiki/Wilks%27_theorem).\n",
    "* [Pearson's Test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test).\n",
    "\n",
    "The $\\chi^2_\\Delta$ Test is most commonly used to investigate the independence of two binary\n",
    "categories in a $2 \\times 2$ contingency table. In this case the difference of the degrees\n",
    "of freedom is exactly $\\Delta = 1$. In this form it is called Pearson's Test.\n",
    "\n",
    "In Python the Pearson's Test is available in the `statistics` module of SciPy.\n",
    "* Statistics [API Documentation](https://docs.scipy.org/doc/scipy/reference/stats.html).\n",
    "* Statistics [User Guide](https://docs.scipy.org/doc/scipy/tutorial/stats.html).\n",
    "* Pearson's Test [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html).\n",
    "* General Contingency Test [Documentation](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chisquare.html).\n",
    "* Cross Tabulation of [Actual Frequencies](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.contingency.crosstab.html)\n",
    "* Estimation of Independent [Expected Frequencies](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.contingency.expected_freq.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual suspects.\n",
    "%matplotlib widget\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mp\n",
    "import numpy as np\n",
    "import ipywidgets as wg\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load\n",
    "\n",
    "We will demonstrate the $\\chi^2_\\Delta$ Test by testing whether survival on the Titanic\n",
    "was independent of gender, or if there was a relationship between gender and survival. We\n",
    "will use the most recent version of the Titanic Passenger Dataset, as of 2016, available\n",
    "from the Vanderbilt Department of Biostatistics' [datasets page](https://hbiostat.org/data/).\n",
    "* Source File `Data\\titanic5.xlsx`\n",
    "* Source Sheet `Titanic5_all`\n",
    "\n",
    "We will use the Pandas\n",
    "[read Excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html)\n",
    "function. Note that the `Price` column is in units of\n",
    "[Pounds, Shillings, Pence](https://en.wikipedia.org/wiki/%C2%A3sd). We will convert this\n",
    "to Decimal Pounds using the factors:\n",
    "* $\\pounds 1 = 20 \\text{s}$\n",
    "* $\\pounds 1 = 240 \\text{d}$\n",
    "\n",
    "Note the the Unicode for the British Pounds sign &pound; is hexidecimal `00A3`, or decimal\n",
    "`0163`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our data\n",
    "embarked = pd.read_excel(\n",
    "    \"Data\\\\titanic5.xlsx\",\n",
    "    sheet_name = \"Titanic5_all\"\n",
    ")\n",
    "\n",
    "# Convert to decimal pounds\n",
    "embarked[\"Decimal Price\"] = (\n",
    "\n",
    "    # Retrieve the pounds\n",
    "    embarked[\"Price\"].str.extract(\"(?<=\\u00A3)([0-9]+)\").astype(float).fillna(0.0) +\n",
    "\n",
    "    # Retrieve the shillings\n",
    "    embarked[\"Price\"].str.extract(\"([0-9]+)(?=s)\").astype(float).fillna(0.0) / 20.0 +\n",
    "\n",
    "    # Retrieve the pence\n",
    "    embarked[\"Price\"].str.extract(\"([0-9]+)(?=d)\").astype(float).fillna(0.0) / 240.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's Test for Independence\n",
    "Pearson's Test for Independence in a $2 \\times 2$ contingency table compares the actual\n",
    "data to the expectation if the dimensions of the contingency table were independent. We\n",
    "start by tabulating the frequencies by dividing the counts in the contingency tables by\n",
    "the total observations.\n",
    "\n",
    "We start by computing the marginal and joint frequencies or fractions:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "    & \\text{Marginal}\\\\\\hline\\\\\n",
    "    f_m & = \\frac{\\# \\text{male} }{ \\# \\text{embarked}}\\\\\\\\\n",
    "    f_d & = \\frac{\\# \\text{died} }{ \\# \\text{embarked}}\\\\\\\\\n",
    "    & \\text{Joint}\\\\\\hline\\\\\n",
    "    f_{m,d} & = \\frac{\\# \\text{male and died} }{ \\# \\text{embarked}}\\\\\\\\\n",
    "    f_{m,l} & = \\frac{\\# \\text{male and survied} }{ \\# \\text{embarked}}\\\\\\\\\n",
    "    f_{w,d} & = \\frac{\\# \\text{female and died} }{ \\# \\text{embarked}}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "The actual frequencies, or *\"the data is what it is\"* model, has three degrees of freedom,\n",
    "the cross tabulated frequencies of survival by gender $f_{m,d}$, $f_{m,l}$, and $f_{w,d}$.\n",
    "$$\n",
    "\\begin{array}{r|cc|c}\n",
    "    & \\text{Died} & \\text{Lived}\\\\\n",
    "    \\hline\n",
    "    \\text{Men} & f_{m,d} & f_{m,l} & f_m\\\\\n",
    "    \\text{Women} & f_{w,d} & 1-f_{m,d}-f_{m,l}-f_{w,d} & 1-f_m\\\\\n",
    "    \\hline\n",
    "    & f_d & 1-f_d\n",
    "\\end{array}\n",
    "$$\n",
    "The expected frequencies, or *\"the survival is independent of gender\"* model, has two\n",
    "degrees of freedom, $f_m$, and $f_d$, the marginal frequencies of survival and gender\n",
    "independently.\n",
    "$$\n",
    "\\begin{array}{r|cc|c}\n",
    "    & \\text{Died} & \\text{Lived}\\\\\n",
    "    \\hline\n",
    "    \\text{Men} & f_m \\cdot f_d & f_m \\cdot (1-f_d) & f_m\\\\\n",
    "    \\text{Women} & (1-f_m) \\cdot f_d & (1-f_m) \\cdot (1-f_d) & 1-f_m\\\\\n",
    "    \\hline\n",
    "    & f_d & 1-f_d\n",
    "\\end{array}\n",
    "$$\n",
    "We determine the degrees of freedom of the test by counting up the number of possible\n",
    "combinations of categorical variables in each model. Next for each model we subtract the\n",
    "number of independent linear constraints. Finally we take the difference between the larger\n",
    "and smaller values:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\Delta &= (2 \\times 2 - 1) - ((2 - 1) + (2 - 1))\\\\\n",
    "       &= 1\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data is what it is\" model\n",
    "actual = st.contingency.crosstab(\n",
    "    \n",
    "    # Gender is the rows\n",
    "    embarked[\"Sex\"],\n",
    "    \n",
    "    # Survival is the columns\n",
    "    embarked[\"Survived\"]\n",
    ")\n",
    "\n",
    "# Row and column margins\n",
    "margins = st.contingency.margins(actual.count)\n",
    "\n",
    "# The \"independence\" model\n",
    "expected = st.contingency.expected_freq(actual.count)\n",
    "\n",
    "# Output\n",
    "print(\"Rows\")\n",
    "print(actual.elements[0])\n",
    "print(margins[0].reshape(1, -1))\n",
    "print(\"\\nColumns\")\n",
    "print(actual.elements[1])\n",
    "print(margins[1].reshape(1, -1))\n",
    "print(\"\\nActual\")\n",
    "print(actual.count)\n",
    "print(\"\\nExpected\")\n",
    "print(expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marimekko Plots of Actual\n",
    "We can illustrate the dependence of survival on gender with Marimekko plots of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank canvas for 2-by-2 Merimekko\n",
    "actualfg, actualax = mp.subplots(2, 2)\n",
    "\n",
    "# Label the figure\n",
    "actualax[0, 0].axis(\"off\")\n",
    "actualax[1, 1].axis(\"off\")\n",
    "actualfg.text(0.20, 0.98, 'Female', ha='center', va='center')\n",
    "actualfg.text(0.40, 0.98, 'Male', ha='center', va='center')\n",
    "actualfg.text(0.60, 0.98, 'Died', ha='center', va='center')\n",
    "actualfg.text(0.80, 0.98, 'Lived', ha='center', va='center')\n",
    "actualfg.text(0.02, 0.80, 'Male', ha='center', va='center', rotation='vertical')\n",
    "actualfg.text(0.02, 0.60, 'Female', ha='center', va='center', rotation='vertical')\n",
    "actualfg.text(0.02, 0.40, 'Lived', ha='center', va='center', rotation='vertical')\n",
    "actualfg.text(0.02, 0.20, 'Died', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Survival as a function of gender\n",
    "actualax[1, 0].bar(\n",
    "    np.cumsum(margins[0]) / np.sum(margins[0]),\n",
    "    actual.count[:, 0] / margins[0].reshape(1, -1)[0],\n",
    "    width = - margins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:pink\", \"tab:blue\" ]\n",
    ")\n",
    "actualax[1, 0].bar(\n",
    "    np.cumsum(margins[0]) / np.sum(margins[0]),\n",
    "    actual.count[:, 1] / margins[0].reshape(1, -1)[0],\n",
    "    bottom = actual.count[:, 0] / margins[0].reshape(1, -1)[0],\n",
    "    width = - margins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"lightpink\", \"lightblue\" ]\n",
    ")\n",
    "\n",
    "# Gender as a function of survival\n",
    "actualax[0, 1].bar(\n",
    "    np.cumsum(margins[1]) / np.sum(margins[1]),\n",
    "    actual.count[0, :] / margins[1].reshape(1, -1)[0],\n",
    "    width = - margins[1].reshape(1, -1)[0] / np.sum(margins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:pink\", \"lightpink\" ]\n",
    ")\n",
    "actualax[0, 1].bar(\n",
    "    np.cumsum(margins[1]) / np.sum(margins[1]),\n",
    "    actual.count[1, :] / margins[1].reshape(1, -1)[0],\n",
    "    bottom = actual.count[0, :] / margins[1].reshape(1, -1)[0],\n",
    "    width = - margins[1].reshape(1, -1)[0] / np.sum(margins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"lightblue\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marimekko Plots of Expected\n",
    "We can illustrate the dependence of survival on gender with Marimekko plots of each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank canvas for 2-by-2 Merimekko\n",
    "expectedfg, expectedax = mp.subplots(2, 2)\n",
    "\n",
    "# Label the figure\n",
    "expectedax[0, 0].axis(\"off\")\n",
    "expectedax[1, 1].axis(\"off\")\n",
    "expectedfg.text(0.20, 0.98, 'Female', ha='center', va='center')\n",
    "expectedfg.text(0.40, 0.98, 'Male', ha='center', va='center')\n",
    "expectedfg.text(0.60, 0.98, 'Died', ha='center', va='center')\n",
    "expectedfg.text(0.80, 0.98, 'Lived', ha='center', va='center')\n",
    "expectedfg.text(0.02, 0.80, 'Male', ha='center', va='center', rotation='vertical')\n",
    "expectedfg.text(0.02, 0.60, 'Female', ha='center', va='center', rotation='vertical')\n",
    "expectedfg.text(0.02, 0.40, 'Lived', ha='center', va='center', rotation='vertical')\n",
    "expectedfg.text(0.02, 0.20, 'Died', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Survival as a function of gender\n",
    "expectedax[1, 0].bar(\n",
    "    np.cumsum(margins[0]) / np.sum(margins[0]),\n",
    "    expected[:, 0] / margins[0].reshape(1, -1)[0],\n",
    "    width = - margins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:pink\", \"tab:blue\" ]\n",
    ")\n",
    "expectedax[1, 0].bar(\n",
    "    np.cumsum(margins[0]) / np.sum(margins[0]),\n",
    "    expected[:, 1] / margins[0].reshape(1, -1)[0],\n",
    "    bottom = expected[:, 0] / margins[0].reshape(1, -1)[0],\n",
    "    width = - margins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"lightpink\", \"lightblue\" ]\n",
    ")\n",
    "\n",
    "# Gender as a function of survival\n",
    "expectedax[0, 1].bar(\n",
    "    np.cumsum(margins[1]) / np.sum(margins[1]),\n",
    "    expected[0, :] / margins[1].reshape(1, -1)[0],\n",
    "    width = - margins[1].reshape(1, -1)[0] / np.sum(margins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:pink\", \"lightpink\" ]\n",
    ")\n",
    "expectedax[0, 1].bar(\n",
    "    np.cumsum(margins[1]) / np.sum(margins[1]),\n",
    "    expected[1, :] / margins[1].reshape(1, -1)[0],\n",
    "    bottom = expected[0, :] / margins[1].reshape(1, -1)[0],\n",
    "    width = - margins[1].reshape(1, -1)[0] / np.sum(margins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"lightblue\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Test\n",
    "In this context a small P-Value of the Pearson's Test indicates that our observation of \n",
    "large difference between the observation of the dependence of survival on gender and\n",
    "survival being independent of gender is unlikely to be due to random chance alone.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pearson's Text. Counts are large enough that we do not need the correction.\n",
    "test = st.chi2_contingency(\n",
    "    actual.count,\n",
    "    correction = False\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(\"Test\")\n",
    "print(f\"Statistic: {test.statistic}\")\n",
    "print(f\"P-Value: {test.pvalue}\")\n",
    "print(f\"Degrees of Freedom: {test.dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The P-Value can be interpreted as meaning **IF** survival is independent of gender **THEN**\n",
    "there is a $5.6 \\times 10^{-106} \\%$ chance of observing the actual data.\n",
    "\n",
    "## Survival by Port of Origin\n",
    "In this example we observe the dependence of survival on the port of origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data is what it is\" model\n",
    "originactual = st.contingency.crosstab(\n",
    "    \n",
    "    # Port is the rows\n",
    "    embarked[\"Joined\"],\n",
    "    \n",
    "    # Survival is the columns\n",
    "    embarked[\"Survived\"]\n",
    ")\n",
    "\n",
    "# Row and column margins\n",
    "originmargins = st.contingency.margins(originactual.count)\n",
    "\n",
    "# The \"independence\" model\n",
    "originexpected = st.contingency.expected_freq(originactual.count)\n",
    "\n",
    "# Output\n",
    "print(\"Ports\")\n",
    "print(originactual.elements[0])\n",
    "print(originmargins[0].reshape(1, -1))\n",
    "print(\"\\nSurvival\")\n",
    "print(originactual.elements[1])\n",
    "print(originmargins[1].reshape(1, -1))\n",
    "print(\"\\nActual\")\n",
    "print(originactual.count)\n",
    "print(\"\\nExpected\")\n",
    "print(originexpected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merimekko of Actual Survival by Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank canvas for 2-by-2 Merimekko\n",
    "originactualfg, originactualax = mp.subplots(2, 2)\n",
    "\n",
    "# Label the figure\n",
    "originactualax[0, 0].axis(\"off\")\n",
    "originactualax[1, 1].axis(\"off\")\n",
    "originactualfg.text(0.15, 0.98, 'Belfast', ha='center', va='center')\n",
    "originactualfg.text(0.20, 0.94, 'Cherbourg', ha='center', va='center')\n",
    "originactualfg.text(0.35, 0.98, 'Queenstown', ha='center', va='center')\n",
    "originactualfg.text(0.40, 0.94, 'Southampton', ha='center', va='center')\n",
    "originactualfg.text(0.60, 0.98, 'Died', ha='center', va='center')\n",
    "originactualfg.text(0.80, 0.98, 'Lived', ha='center', va='center')\n",
    "originactualfg.text(0.02, 0.60, 'Belfast', ha='center', va='center', rotation='vertical')\n",
    "originactualfg.text(0.06, 0.65, 'Cherbourg', ha='center', va='center', rotation='vertical')\n",
    "originactualfg.text(0.02, 0.80, 'Queenstown', ha='center', va='center', rotation='vertical')\n",
    "originactualfg.text(0.06, 0.85, 'Southampton', ha='center', va='center', rotation='vertical')\n",
    "originactualfg.text(0.02, 0.40, 'Lived', ha='center', va='center', rotation='vertical')\n",
    "originactualfg.text(0.02, 0.20, 'Died', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Survival as a function of origin\n",
    "originactualax[1, 0].bar(\n",
    "    np.cumsum(originmargins[0]) / np.sum(originmargins[0]),\n",
    "    originactual.count[:, 0] / originmargins[0].reshape(1, -1)[0],\n",
    "    width = - originmargins[0].reshape(1, -1)[0] / np.sum(originmargins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\" ]\n",
    ")\n",
    "originactualax[1, 0].bar(\n",
    "    np.cumsum(originmargins[0]) / np.sum(originmargins[0]),\n",
    "    originactual.count[:, 1] / originmargins[0].reshape(1, -1)[0],\n",
    "    bottom = originactual.count[:, 0] / originmargins[0].reshape(1, -1)[0],\n",
    "    width = - originmargins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"lightblue\", \"wheat\", \"lightgreen\", \"salmon\" ]\n",
    ")\n",
    "\n",
    "# Origin as a function of survival\n",
    "originactualax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originactual.count[0, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"lightblue\" ]\n",
    ")\n",
    "originactualax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originactual.count[1, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = originactual.count[0, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:orange\", \"wheat\" ]\n",
    ")\n",
    "originactualax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originactual.count[2, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = (originactual.count[0, :] + originactual.count[1, :]) / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:green\", \"lightgreen\" ]\n",
    ")\n",
    "originactualax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originactual.count[3, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = (originactual.count[0, :] + originactual.count[1, :] + originactual.count[2, :]) / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:red\", \"salmon\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merimekko of Expected Survival by Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blank canvas for 2-by-2 Merimekko\n",
    "originexpectedfg, originexpectedax = mp.subplots(2, 2)\n",
    "\n",
    "# Label the figure\n",
    "originexpectedax[0, 0].axis(\"off\")\n",
    "originexpectedax[1, 1].axis(\"off\")\n",
    "originexpectedfg.text(0.15, 0.98, 'Belfast', ha='center', va='center')\n",
    "originexpectedfg.text(0.20, 0.94, 'Cherbourg', ha='center', va='center')\n",
    "originexpectedfg.text(0.35, 0.98, 'Queenstown', ha='center', va='center')\n",
    "originexpectedfg.text(0.40, 0.94, 'Southampton', ha='center', va='center')\n",
    "originexpectedfg.text(0.60, 0.98, 'Died', ha='center', va='center')\n",
    "originexpectedfg.text(0.80, 0.98, 'Lived', ha='center', va='center')\n",
    "originexpectedfg.text(0.02, 0.60, 'Belfast', ha='center', va='center', rotation='vertical')\n",
    "originexpectedfg.text(0.06, 0.65, 'Cherbourg', ha='center', va='center', rotation='vertical')\n",
    "originexpectedfg.text(0.02, 0.80, 'Queenstown', ha='center', va='center', rotation='vertical')\n",
    "originexpectedfg.text(0.06, 0.85, 'Southampton', ha='center', va='center', rotation='vertical')\n",
    "originexpectedfg.text(0.02, 0.40, 'Lived', ha='center', va='center', rotation='vertical')\n",
    "originexpectedfg.text(0.02, 0.20, 'Died', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "# Survival as a function of origin\n",
    "originexpectedax[1, 0].bar(\n",
    "    np.cumsum(originmargins[0]) / np.sum(originmargins[0]),\n",
    "    originexpected[:, 0] / originmargins[0].reshape(1, -1)[0],\n",
    "    width = - originmargins[0].reshape(1, -1)[0] / np.sum(originmargins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\" ]\n",
    ")\n",
    "originexpectedax[1, 0].bar(\n",
    "    np.cumsum(originmargins[0]) / np.sum(originmargins[0]),\n",
    "    originexpected[:, 1] / originmargins[0].reshape(1, -1)[0],\n",
    "    bottom = originexpected[:, 0] / originmargins[0].reshape(1, -1)[0],\n",
    "    width = - originmargins[0].reshape(1, -1)[0] / np.sum(margins[0]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"lightblue\", \"wheat\", \"lightgreen\", \"salmon\" ]\n",
    ")\n",
    "\n",
    "# Origin as a function of survival\n",
    "originexpectedax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originexpected[0, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:blue\", \"lightblue\" ]\n",
    ")\n",
    "originexpectedax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originexpected[1, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = originexpected[0, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:orange\", \"wheat\" ]\n",
    ")\n",
    "originexpectedax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originexpected[2, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = (originexpected[0, :] + originexpected[1, :]) / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:green\", \"lightgreen\" ]\n",
    ")\n",
    "originexpectedax[0, 1].bar(\n",
    "    np.cumsum(originmargins[1]) / np.sum(originmargins[1]),\n",
    "    originexpected[3, :] / originmargins[1].reshape(1, -1)[0],\n",
    "    bottom = (originexpected[0, :] + originexpected[1, :] + originexpected[2, :]) / originmargins[1].reshape(1, -1)[0],\n",
    "    width = - originmargins[1].reshape(1, -1)[0] / np.sum(originmargins[1]),\n",
    "    align = \"edge\",\n",
    "    color = [ \"tab:red\", \"salmon\" ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Test\n",
    "Our observation of a dependence of survival on the port of origin is statistically\n",
    "significant. The degrees of freedom is given by:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\Delta &= (2 \\times 4 - 1) - ((2 - 1) + (4 - 1))\\\\\n",
    "       &= 3\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pearson's Text. Counts are large enough that we do not need the correction.\n",
    "origintest = st.chi2_contingency(\n",
    "    originactual.count,\n",
    "    correction = False\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(\"Test\")\n",
    "print(f\"Statistic: {origintest.statistic}\")\n",
    "print(f\"P-Value: {origintest.pvalue}\")\n",
    "print(f\"Degrees of Freedom: {origintest.dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The P-Value can be interpreted as meaning **IF** survival is independent of the port of\n",
    "origin **THEN** there is an $1.2 \\times 10^{-17}\\%$ chance of observing the actual data.\n",
    "\n",
    "## Statistical Testing Hierarchy\n",
    "There are many possible explanations for the relationships we have seen so far. For\n",
    "instance, there maybe a relationship between gender and port of origin that accounts for\n",
    "the dependence of survival on the port of origin. To proceed we must first take a step\n",
    "back.\n",
    "\n",
    "Recall from our lecture on Biases, Fallacies, and Paradoxes that there are many ways we\n",
    "can misinterpret and misrepresent our analysis. In fact, the examples we have covered so\n",
    "far are vulnerable to the Multiple Comparisons Fallacy. By comparing variables pairwise we\n",
    "risk identifying spurious relationships, those due to chance alone, as being meaningful. How\n",
    "do we decrease the risk of the Multiple Comparisons Fallacy?\n",
    "\n",
    "We conduct our tests through a hierarchy of comparisons. We start by comparing the simplest\n",
    "model to the most complex. In our case we would compare a model that assumes all the \n",
    "variables are independent to the \"data is what it is\", where all the variables depend on\n",
    "each other. This test is called the Omnibus Test.\n",
    "\n",
    "In the Titanic dataset we will consider the four variables:\n",
    "1. Gender\n",
    "2. Port of Origin\n",
    "3. Class or Department\n",
    "4. Survival\n",
    "\n",
    "The Omnibus test compares the completely independent model.\n",
    "$$\n",
    "\\operatorname{\\mathbb{P}}[\\text{Srv}, \\text{Gdr}, \\text{Cls}, \\text{Prt}] =\n",
    "\\operatorname{\\mathbb{P}}[\\text{Srv}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Gdr}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Cls}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Prt}]\n",
    "$$\n",
    "To the \"data is what is model\", where we cannot resolve any independence.\n",
    "$$\n",
    "\\operatorname{\\mathbb{P}}[\\text{Srv}, \\text{Gdr}, \\text{Cls}, \\text{Prt}]\n",
    "$$\n",
    "If the Omnibus Test is significant then we can work inwards, recursively eliminating models\n",
    "through judicious comparisons. In the Titanic example, our next step is to test if Survival\n",
    "is independent of Port of Origin given the gender and class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"data is what it is\" model\n",
    "omnibusactual = st.contingency.crosstab(\n",
    "\n",
    "    # Gender is first dimension\n",
    "    embarked[\"Sex\"],\n",
    "    \n",
    "    # Port is the second dimension\n",
    "    embarked[\"Joined\"],\n",
    "\n",
    "    # Passenger class or crew department is the third dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False),\n",
    "    \n",
    "    # Survival is the final dimension\n",
    "    embarked[\"Survived\"]\n",
    ")\n",
    "\n",
    "# Row and column margins\n",
    "omnibusmargins = st.contingency.margins(omnibusactual.count)\n",
    "\n",
    "# The \"independence\" model\n",
    "omnibusexpected = st.contingency.expected_freq(omnibusactual.count)\n",
    "\n",
    "# Output\n",
    "print(\"Genders\")\n",
    "print(omnibusactual.elements[0])\n",
    "print(omnibusmargins[0].reshape(1, -1))\n",
    "print(\"\\nPorts\")\n",
    "print(omnibusactual.elements[1])\n",
    "print(omnibusmargins[1].reshape(1, -1))\n",
    "print(\"\\nClasses\")\n",
    "print(omnibusactual.elements[2])\n",
    "print(omnibusmargins[2].reshape(1, -1))\n",
    "print(\"\\nSurvival\")\n",
    "print(omnibusactual.elements[3])\n",
    "print(omnibusmargins[3].reshape(1, -1))\n",
    "print(\"\\nActual\")\n",
    "print(omnibusactual.count)\n",
    "print(\"\\nExpected\")\n",
    "print(omnibusexpected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omnibus Statistical Test\n",
    "The Omnibus Statistical test is significant, as was expected. We can now proceed to see if\n",
    "survival is conditionally independent of port of origin, after we have accounted for gender\n",
    "and class. Our degrees of freedom calculation:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\Delta &= (2 \\times 2 \\times 8 \\times 4 - 1) -\n",
    "((2 - 1) + (2 - 1) + (8 - 1) + (4 - 1))\\\\\n",
    "       &= 115\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Pearson's Text\n",
    "omnibustest = st.chi2_contingency(\n",
    "    omnibusactual.count,\n",
    "    correction = False\n",
    ")\n",
    "\n",
    "# Output\n",
    "print(\"Test\")\n",
    "print(f\"Statistic: {omnibustest.statistic}\")\n",
    "print(f\"P-Value: {omnibustest.pvalue}\")\n",
    "print(f\"Degrees of Freedom: {omnibustest.dof}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "The P-Value can be interpreted as meaning **IF** all the variables were independent of each\n",
    "other **THEN** there is an 0% chance of observing the actual data.\n",
    "\n",
    "### Test for Conditional Independence\n",
    "To construct a test for the conditional independence of survival from the port of origin we\n",
    "first have to build a model for Survival, as mediated by gender and class or department.\n",
    "$$\n",
    "\\operatorname{\\mathbb{P}}[\\text{Srv}, \\text{Gdr}, \\text{Cls}, \\text{Prt}] =\n",
    "\\operatorname{\\mathbb{P}}[\\text{Srv} \\| \\text{Gdr}, \\text{Cls}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Gdr}, \\text{Cls} \\| \\text{Prt}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Prt}]\n",
    "$$\n",
    "The furthest right probability is simply the marginal distribution of embarked over the\n",
    "cities of origin. This does nothing more than simple measure the relative volume of embarked\n",
    "for each port.\n",
    "\n",
    "The middle probability is the conditional distribution of genders and classes or departments on\n",
    "the port of origin. This measures how the genders and classes or departments varied by port.\n",
    "For example, most of the crew embarked from Belfast, most steerage embarked from\n",
    "Southampton, and Cherbourg embarked mostly first class passengers and their attendants.\n",
    "\n",
    "The probability to the immediate right of the equality operator is the distribution of\n",
    "survival conditioned on gender and class or department. This measures the risk faced by\n",
    "each combination of gender and class or department. If we observe that survival is\n",
    "conditionally independent of the port of origin than we can further investigate to see\n",
    "if the survival risks were compounding in gender and class or department.\n",
    "\n",
    "Multiplying both sides of the model by the actual number of embarked tells us how to \n",
    "compute are model of expected survival from the actual marginal counts.\n",
    "$$\n",
    "\\operatorname{\\mathbb{E}}\\#[\\text{Srv}, \\text{Gdr}, \\text{Cls}, \\text{Prt}] =\n",
    "\\frac{\\#[\\text{Srv}, \\text{Gdr}, \\text{Cls}]}\n",
    "{\\#[\\text{Gdr}, \\text{Cls}]} \\cdot\n",
    "\\#[\\text{Gdr}, \\text{Cls}, \\text{Prt}]\n",
    "$$\n",
    "Each term on the right hand side is simply the counts from the respective contingency table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival, Gender, Class-Department contingency\n",
    "survivalactual = st.contingency.crosstab(\n",
    "\n",
    "    # Survival is first dimension\n",
    "    embarked[\"Survived\"],\n",
    "    \n",
    "    # Gender is the second dimension\n",
    "    embarked[\"Sex\"],\n",
    "    \n",
    "    # Passenger class or crew department is the final dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False)\n",
    ")\n",
    "\n",
    "# Gender, Class-Department contingency\n",
    "genderactual = st.contingency.crosstab(\n",
    "\n",
    "    # Gender is first dimension\n",
    "    embarked[\"Sex\"],\n",
    "\n",
    "    # Passenger class or crew department is the final dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False)\n",
    ")\n",
    "\n",
    "# Gender, Class-Department, Port contingency\n",
    "portactual = st.contingency.crosstab(\n",
    "\n",
    "    # Gender is first dimension\n",
    "    embarked[\"Sex\"],\n",
    "\n",
    "    # Passenger class or crew department is the second dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False),\n",
    "    \n",
    "    # Port is the final dimension\n",
    "    embarked[\"Joined\"]\n",
    ")\n",
    "\n",
    "# Contingency tables\n",
    "print(\"Survival, Gender, Class or Department\")\n",
    "print(survivalactual.count)\n",
    "print(\"\\nGender, Class or Department\")\n",
    "print(genderactual.count)\n",
    "print(\"\\nGender, Class or Department, Port\")\n",
    "print(portactual.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Contingency\n",
    "We re-run the same cross tabulation of the actual contingency table as for the Omnibus test,\n",
    "except we change the order of the variables to match the order of the model:\n",
    "1. Survival\n",
    "2. Gender\n",
    "3. Class or Department\n",
    "4. Port of Origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionalactual = st.contingency.crosstab(\n",
    "\n",
    "    # Survival is first dimension\n",
    "    embarked[\"Survived\"],\n",
    "\n",
    "    # Gender is second dimension\n",
    "    embarked[\"Sex\"],\n",
    "\n",
    "    # Passenger class or crew department is the third dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False),\n",
    "    \n",
    "    # Port is the final dimension\n",
    "    embarked[\"Joined\"]\n",
    ")\n",
    "print(\"Actual Survival, Gender, Class or Department, Port\")\n",
    "print(conditionalactual.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Munging\n",
    "To calculate the expected conditional survival we need to undertake a bit of index munging\n",
    "using NumPy's [Einstein Summation](https://numpy.org/doc/stable/reference/generated/numpy.einsum.html)\n",
    "to compute the element wise multiplications and divisions.\n",
    "$$\n",
    "\\operatorname{\\mathbb{E}}\\operatorname{Num}_{\\text{Srv}, \\text{Gdr}, \\text{Cls}, \\text{Prt}} =\n",
    "\\operatorname{Num}_{\\text{Srv}, \\text{Gdr}, \\text{Cls}} \\cdot\n",
    "\\frac{1}{\\operatorname{Num}_{\\text{Gdr}, \\text{Cls}}} \\cdot\n",
    "\\operatorname{Num}_{\\text{Gdr}, \\text{Cls}, \\text{Prt}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditionalexpected = np.einsum(\n",
    "\n",
    "    # How to combine the values in the variable dimensions\n",
    "    \"sgc,gc,gcp->sgcp\",\n",
    "\n",
    "    # Multiply by the joint count of survival, gender, class\n",
    "    survivalactual.count,\n",
    "\n",
    "    # Divide by the joint count of gender and class\n",
    "    1 / np.maximum(1, genderactual.count),\n",
    "\n",
    "    # Multiply by the joint count of gender, class, and port\n",
    "    portactual.count\n",
    ")\n",
    "print(\"Expected Survival, Gender, Class or Department, Port\")\n",
    "print(conditionalexpected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Control\n",
    "We can quickly test to make sure our model is minimal plausible by seeing if the totals of\n",
    "expected and actual are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Actual: {np.sum(conditionalactual.count)}\")\n",
    "print(f\"Expected: {np.sum(conditionalexpected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of Conditional Independence\n",
    "Since we have compiled our own expected model we will use the $\\chi^2_\\Delta$ \n",
    "[distribution](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html)\n",
    "from the SciPy library. This is necessary for two reasons: first, the prebuilt tests only\n",
    "compare complete independence to complete dependence; second, the prebuilt tests require all\n",
    "the contingency cells of both actual and expected to be greater than zero. However, since we\n",
    "are calculating an expected from the conditional and marginal distributions of the actual\n",
    "data we know that our expected probabilities will only every be zero when the actual\n",
    "probability is zero.\n",
    "\n",
    "We will use the G-Statistic, where our cells are over every combination of categorical\n",
    "variable values in our contingency table:\n",
    "$$\n",
    "g = 2 \\cdot \\sum_{\\text{cell } \\in \\text{ cells}}\n",
    "\\#\\text{act}_{\\text{cell}} \\cdot \\left(\n",
    "       \\log(\\#\\text{act}_{\\text{cell}}) -\n",
    "       \\log(\\#\\text{exp}_{\\text{cell}})\n",
    "\\right)\n",
    "$$\n",
    "Our degrees of freedom will be:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\Delta &= (2 \\times 2 \\times 8 \\times 4 - 1) - (\n",
    "       (2 \\times 2 \\times 8 - 1) +\n",
    "       (2 \\times 8 \\times 4 - 2 \\times 8)\n",
    ")\\\\\n",
    "       &= 48\n",
    "\\end{array}\n",
    "$$\n",
    "Our significance test is then given by the tail probability of the $\\chi^2_\\Delta$\n",
    "distribution:\n",
    "$$\n",
    "\\alpha = 1 - \\operatorname{\\chi^2_{48}}[G < g]\n",
    "$$\n",
    "Note we will use a little trick of lower truncating the actual and expected counts in the\n",
    "logarithm at one. This will cause the logarithm to return zero, which is fine because the\n",
    "expected counts will only be zero if the actual counts are zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summing over all the cells in the table\n",
    "gstatistic = 2 * np.sum(\n",
    "\n",
    "    # The actual frequencies\n",
    "    conditionalactual.count * (\n",
    "\n",
    "        # Log of actual frequencies\n",
    "        np.log(np.maximum(1, conditionalactual.count)) -\n",
    "\n",
    "        # Log of expected frequencies\n",
    "        np.log(np.maximum(1, conditionalexpected))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tail probability\n",
    "gtest = 1 - st.chi2(48).cdf(gstatistic)\n",
    "\n",
    "# Output\n",
    "print(\"Test\")\n",
    "print(f\"G Statistic: {gstatistic}\")\n",
    "print(f\"P-Value: {gtest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "Once we have accounted for the distribution of gender and class or department across ports\n",
    "of origin we find that survival is conditionally independent of the port of origin. This\n",
    "means for all future analysis, provided we include gender and class or department, we can\n",
    "exclude port of origin from the analysis.\n",
    "\n",
    "The P-Value can be interpreted as meaning **IF** survival is conditionally independent of\n",
    "the port of origin **THEN** there is an 85% chance of observing the actual data.\n",
    "\n",
    "### Compound Hazard Model\n",
    "With port of origin accounted for, we can now proceed to investigate whether the risks due\n",
    "to gender and class interacted individually or more simply compounded. For this model\n",
    "every the hazard of dying requires both the chances of gender and class being against\n",
    "the person:\n",
    "$$\n",
    "\\operatorname{\\mathbb{P}}[\\text{Died}, \\text{Gdr}, \\text{Cls}] =\n",
    "\\operatorname{\\mathbb{P}}[\\text{Died} \\| \\text{Gdr}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Died} \\| \\text{Cls}] \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Gdr}, \\text{Cls}]\n",
    "$$\n",
    "And conversely the probability of dying is given by one minus the conditional probabilities:\n",
    "$$\n",
    "\\operatorname{\\mathbb{P}}[\\text{Lived}, \\text{Gdr}, \\text{Cls}] = \\left(\n",
    "    1 - \\operatorname{\\mathbb{P}}[\\text{Died} \\| \\text{Gdr}] \\cdot\n",
    "    \\operatorname{\\mathbb{P}}[\\text{Died} \\| \\text{Cls}]\n",
    "\\right) \\cdot\n",
    "\\operatorname{\\mathbb{P}}[\\text{Gdr}, \\text{Cls}]\n",
    "$$\n",
    "The degrees of freedom is then:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\Delta &= (2 \\times 2 \\times 8 - 1) - (2 + 8 + (2 \\times 8 - 1))\\\\\n",
    "       &= 6\n",
    "\\end{array}\n",
    "$$\n",
    "We can interpret this model as saying that we have to take the socio-demographic\n",
    "distribution of gender and class or department for what it is, and that given a gender and\n",
    "class or department the risks multiply.\n",
    "$$\n",
    "\\operatorname{\\mathbb{E}}\\operatorname{Num}_{\\text{Die}, \\text{Gdr}, \\text{Cls}} =\n",
    "\\frac{\\operatorname{Num}_{\\text{Die}, \\text{Gdr}}}{\\operatorname{Num}_{\\text{Gdr}}} \\cdot\n",
    "\\frac{\\operatorname{Num}_{\\text{Die}, \\text{Cls}}}{\\operatorname{Num}_{\\text{Cls}}} \\cdot\n",
    "\\operatorname{Num}_{\\text{Gdr}, \\text{Cls}}\n",
    "$$\n",
    "Likewise\n",
    "$$\n",
    "\\operatorname{\\mathbb{E}}\\operatorname{Num}_{\\text{Lvd}, \\text{Gdr}, \\text{Cls}} = \\left(\n",
    "    1 - \n",
    "    \\frac{\\operatorname{Num}_{\\text{Die}, \\text{Gdr}}}{\\operatorname{Num}_{\\text{Gdr}}} \\cdot\n",
    "    \\frac{\\operatorname{Num}_{\\text{Die}, \\text{Cls}}}{\\operatorname{Num}_{\\text{Cls}}}\n",
    "\\right) \\cdot\n",
    "\\operatorname{Num}_{\\text{Gdr}, \\text{Cls}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Survival, Gender, Class or Department\n",
      "[[[  5  12 110   0   0   0   0   3]\n",
      "  [118 146 418   8  23 253  66 334]]\n",
      "\n",
      " [[139  94 106   0   0   0   2  18]\n",
      "  [ 62  24  75   0  43  72   1  76]]]\n",
      "\n",
      "Expected Survival, Gender, Class or Department\n",
      "[[[ 14.53306067  16.13200557  42.76376474   0.           0.\n",
      "     0.           0.50858007   4.36522284]\n",
      "  [ 54.30095016  77.33422701 291.74903571   6.35718441  18.27690518\n",
      "   201.04595695  50.92657511 254.74830913]]\n",
      "\n",
      " [[129.46693933  89.86799443 173.23623526   0.           0.\n",
      "     0.           1.49141993  16.63477716]\n",
      "  [125.69904984  92.66577299 201.25096429   1.64281559  47.72309482\n",
      "   123.95404305  16.07342489 155.25169087]]]\n",
      "\n",
      "Check Sum\n",
      "Actual: 2208\n",
      "Expected: 2208.0\n"
     ]
    }
   ],
   "source": [
    "# Allocate space for the expected model without ports\n",
    "compoundexpected = np.zeros((2, 2, 8))\n",
    "\n",
    "# Survival and gender\n",
    "compoundgenderactual = st.contingency.crosstab(\n",
    "\n",
    "    # Survival is first dimension\n",
    "    embarked[\"Survived\"],\n",
    "\n",
    "    # Gender is final dimension\n",
    "    embarked[\"Sex\"]\n",
    ")\n",
    "\n",
    "# Survival and class\n",
    "compoundclassactual = st.contingency.crosstab(\n",
    "\n",
    "    # Survival is first dimension\n",
    "    embarked[\"Survived\"],\n",
    "\n",
    "    # Passenger class or crew department is the final dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False)\n",
    ")\n",
    "\n",
    "# Demographics\n",
    "compounddemographicsactual = st.contingency.crosstab(\n",
    "\n",
    "    # Gender is first dimension\n",
    "    embarked[\"Sex\"],\n",
    "\n",
    "    # Passenger class or crew department is the final dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False)\n",
    ")\n",
    "\n",
    "# Actual joint counts\n",
    "compoundactual = st.contingency.crosstab(\n",
    "\n",
    "    # Survival is first dimension\n",
    "    embarked[\"Survived\"],\n",
    "\n",
    "    # Gender is second dimension\n",
    "    embarked[\"Sex\"],\n",
    "\n",
    "    # Passenger class or crew department is the final dimension\n",
    "    embarked[\"Class\"].astype(str, copy = False)\n",
    ")\n",
    "\n",
    "# Row and column margins\n",
    "compoundmargins = st.contingency.margins(compoundactual.count)\n",
    "\n",
    "\n",
    "# Build the model\n",
    "compoundconditonal = np.einsum(\n",
    "    \"g,c->gc\",\n",
    "    compoundgenderactual.count[0, :] / compoundmargins[1].reshape(1, -1)[0],\n",
    "    compoundclassactual.count[0, :] / compoundmargins[2].reshape(1, -1)[0]\n",
    ")\n",
    "compoundexpected[0, :, :] = np.einsum(\n",
    "    \"gc,gc->gc\",\n",
    "    compoundconditonal,\n",
    "    compounddemographicsactual.count\n",
    ")\n",
    "compoundexpected[1, :, :] = np.einsum(\n",
    "    \"gc,gc->gc\",\n",
    "    1 - compoundconditonal,\n",
    "    compounddemographicsactual.count\n",
    ")\n",
    "\n",
    "# Check\n",
    "print(\"Actual Survival, Gender, Class or Department\")\n",
    "print(compoundactual.count)\n",
    "print(\"\\nExpected Survival, Gender, Class or Department\")\n",
    "print(compoundexpected)\n",
    "print(\"\\nCheck Sum\")\n",
    "print(f\"Actual: {np.sum(compoundactual.count)}\")\n",
    "print(f\"Expected: {np.sum(compoundexpected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for Significance\n",
    "We can observe that our compound hazard model has a heterogeneous discrepancies in the\n",
    "mortality estimates.\n",
    "1. Female mortality in first and second class is overestimated, while third is\n",
    "underestimated.\n",
    "2. Overall male mortality is underestimated.\n",
    "\n",
    "From the statistical significance of the G-Statistic we can conclude that the mis-estimation\n",
    "of the model is large enough that it is highly unlikely the actual mortality can be\n",
    "explained by our compound hazard model.\n",
    "\n",
    "In more process orientated terms, class and gender interacted by more than just compounding\n",
    "hazards. Being a first or second class female passenger afforded more protection than simply\n",
    "both alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n",
      "G Statistic: 629.1086201109069\n",
      "P-Value: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Summing over all the cells in the table\n",
    "compoundgstatistic = 2 * np.sum(\n",
    "\n",
    "    # The actual frequencies\n",
    "    compoundactual.count * (\n",
    "\n",
    "        # Log of actual frequencies\n",
    "        np.log(np.maximum(1, compoundactual.count)) -\n",
    "\n",
    "        # Log of expected frequencies\n",
    "        np.log(np.maximum(1, compoundexpected))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Tail probability\n",
    "compoundgtest = 1 - st.chi2(6).cdf(compoundgstatistic)\n",
    "\n",
    "# Output\n",
    "print(\"Test\")\n",
    "print(f\"G Statistic: {compoundgstatistic}\")\n",
    "print(f\"P-Value: {compoundgtest}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
