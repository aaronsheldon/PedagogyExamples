{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested Data\n",
    "\n",
    "Nested data structures, also known as hierarchical or tree data structures are any data\n",
    "structure that can recursively contain more data. Imagine fitting backpacks within\n",
    "backpacks. One of the more common activities in data analysis is converting nested data\n",
    "into tabular data.\n",
    "\n",
    "## Serialization\n",
    "\n",
    "The process of turning a nested data structure into a flat text representation.\n",
    "\n",
    "## Parsing\n",
    "\n",
    "Also know as Deserialization, or marshalling. The reverse process of turning flat text into\n",
    "a nested data structure. You cannot generate nested or hierarchical data structures using\n",
    "regular expressions. Nor can you even represent searches, such as find the fifth nested\n",
    "deep tag.\n",
    "\n",
    "Overall, any algorithm for converting flat text into a tree-like or recursive data\n",
    "structure.\n",
    "\n",
    "## Indirection\n",
    "\n",
    "Instead of embedding data within the data structure instead pointers are used. The parent \n",
    "data contains pointers to the child data. In the backpack analogy, instead of having\n",
    "backpacks full of backpacks, each backpack contains notes saying which backpacks to look\n",
    "in next.\n",
    "\n",
    "## Breadth First\n",
    "\n",
    "In breadth first searches, enumeration, and serialization, we step through the highest\n",
    "siblings first. This is analogous to database normalization, where we first create a table\n",
    "of all the parents, then a table of all the immediate children, then a table of all the\n",
    "grandchildren, and so on.\n",
    "\n",
    "## Depth First\n",
    "\n",
    "In depth first searches, enumeration, and serialization we go down the rabbit hole from the\n",
    "root of the tree, listing the first parent, then their first child, then their first\n",
    "grandchild, unit we can go no further. We then step back until we find a level with more\n",
    "sibling nodes. Most of the modern text serializations, like JSON, and XML are depth first\n",
    "representations, with the degree of textual nesting representing the tree depth.\n",
    "\n",
    "## Examples of Nested Data\n",
    "\n",
    "* Nested Python lists, tuples, and dictionaries\n",
    "* File systems\n",
    "* [Document Object Model](https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model)\n",
    "of a webpage\n",
    "\n",
    "## Examples of Serialized Data\n",
    "\n",
    "* [JSON](https://www.json.org/json-en.html)\n",
    "* [HTML](https://html.spec.whatwg.org/multipage/)\n",
    "* [XML](https://www.w3.org/TR/xml11/)\n",
    "* [Any computer language](https://en.wikipedia.org/wiki/Context-free_grammar)\n",
    "\n",
    "## Branching\n",
    "\n",
    "Hierarchical data structures are formed by branching in one direction. These are also called\n",
    "edges, or paths.\n",
    "\n",
    "## Leafs\n",
    "\n",
    "The end of branch is called a leaf, node, child, or vertex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GITURL = \"https://api.github.com/events\"\n",
    "with requests.get(GITURL) as r:\n",
    "    eventsjson= r.json()\n",
    "    eventstext = r.text\n",
    "print(type(eventsjson))\n",
    "print(len(eventsjson))\n",
    "print(eventsjson[0])\n",
    "eventsload = json.loads(eventstext)\n",
    "print(eventsload[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets practice some navigation and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(eventsjson[0][\"actor\"], indent = 4))\n",
    "print(eventsjson[0][\"actor\"])\n",
    "print(eventsload[0][\"actor\"])\n",
    "print(type(eventsjson))\n",
    "print(type(eventsload))\n",
    "print(len(eventsjson))\n",
    "print(len(eventsload))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Nested Data to Tables\n",
    "\n",
    "Below is a small example of typical code we would run to convert a list of nested data\n",
    "structures to a list of rows, and then finally as single table. To do so we have to pick\n",
    "the data we want from the nested data structure and say which column to place the data. We\n",
    "will implement this using the \n",
    "[Pandas from records](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.from_records.html)\n",
    "method and list comprehensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping(item):\n",
    "    \"\"\" In general this dictionary is the only part that you should change. The keys are the\n",
    "    columns of the dataframe, and their values are single item lists that contain the value\n",
    "    for the row in the column. Just use regular dictionary indexing to extract the value\n",
    "    you want:\n",
    "    * `record` item flattened into a record dictionary.\"\"\"\n",
    "    return {\n",
    "                    \n",
    "        # Event column, value is the event name\n",
    "        \"event\": item[\"type\"],\n",
    "\n",
    "        # Repository column, value is the repository name.\n",
    "        \"repository\": item[\"repo\"][\"name\"],\n",
    "\n",
    "        #  Created, value is the time of the transaction\n",
    "        \"created\": pd.to_datetime(item[\"created_at\"])\n",
    "    }\n",
    "\n",
    "def tabulate(items, mapping):\n",
    "    \"\"\" Turn a list of items into a dataframe using the supplied record mapping function:\n",
    "    * `df` dateframe of records\"\"\"\n",
    "    return pd.DataFrame.from_records([ mapping(i) for i in items ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the tabulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tabulate(eventsjson, mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets go from a Python tree-structure of dictionaries and lists to flat JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originaldata = [\n",
    "    \"Calgary\",\n",
    "    45,\n",
    "    {\n",
    "        \"a\": 3,\n",
    "        4: \"b\",\n",
    "        \"a method\": \"def mymethod(a,b): return a+b\"\n",
    "    },\n",
    "    \"Edmonton\"\n",
    "]\n",
    "print(originaldata)\n",
    "serializedjson = json.dumps(originaldata, indent = 4)\n",
    "print(serializedjson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the reverse process of starting with some JSON and parsing into a tree-structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsontext = \"\"\"[\n",
    "    45,\n",
    "    43,\n",
    "    -90,\n",
    "    -80,\n",
    "    [\n",
    "        { \"a\": \"b\", \"c\": \"d\" },\n",
    "        {\n",
    "            \"q\": \"u\",\n",
    "            \"z\": [ \"y\", \"x\" ]\n",
    "        }\n",
    "    ]\n",
    "]\"\"\"\n",
    "print(jsontext)\n",
    "loadtext = json.loads(jsontext)\n",
    "print(type(jsontext))\n",
    "print(type(loadtext))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little more practice navigating the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loadtext[-1][-2])\n",
    "print(json.dumps(loadtext, indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some library documentation for serializing and marshalling:\n",
    "\n",
    "* [Python JSON](https://docs.python.org/3/library/json.html)\n",
    "* [Python HTML](https://docs.python.org/3/library/html.parser.html)\n",
    "* [Python XML](https://docs.python.org/3/library/xml.html)\n",
    "* [Beautiful Soup](https://beautiful-soup-4.readthedocs.io/en/latest/)\n",
    "\n",
    "We will demonstrate using Beautiful Soup to create a dataframe from HTML5 text. Our goal\n",
    "is to find and use the data on the\n",
    "[Wikipedia page listing gravitational waves](https://en.wikipedia.org/wiki/List_of_gravitational_wave_observations)\n",
    "to create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WIKIURL = \"https://en.wikipedia.org/wiki/List_of_gravitational_wave_observations\"\n",
    "with requests.get(WIKIURL) as r:\n",
    "    pagetext = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prove that page text is just plain text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagetext[0:1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the flat text into a tree-like or recursive data structure. This way we can navigate\n",
    "the data programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pagesoup = soup(pagetext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the parse structure is an object, and has a method that returns the formatted\n",
    "text. The print the formatted text and compare to the original source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pagesoup))\n",
    "print(type(pagesoup.prettify()))\n",
    "print(pagesoup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the soup object model using the dot notation to access the first tag of\n",
    "each type of tag. Each tag contains more...tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(pagesoup.html))\n",
    "print(type(pagesoup.html.head))\n",
    "print(type(pagesoup.html.head.title))\n",
    "print(pagesoup.html.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `find_all()` function selects all the tags of a particular type, from the current\n",
    "location deeper into the nested tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pagesoup.html.head.find_all(\"script\")))\n",
    "print(len(pagesoup.html.head.contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conjunction with the `string` property and a list comprehension we can, for example,\n",
    "get all the contents of all the script tags in the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsscripts = [ t.string for t in pagesoup.html.head.find_all(\"script\") ]\n",
    "print(type(jsscripts[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the first table in the document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pagesoup.table.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now retrieve all the tables in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n"
     ]
    }
   ],
   "source": [
    "# List every table in the document\n",
    "candidates = pagesoup.find_all(\"table\")\n",
    "print(len(candidates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter that list for just those tables with captions, and verify the fourth table in the\n",
    "list is the one we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<caption>Marginal event detections\n",
      "</caption>\n"
     ]
    }
   ],
   "source": [
    "# Extract the captions that are available\n",
    "captionedtables = [ c for c in candidates if c.caption is not None]\n",
    "print(captionedtables[3].caption)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets grab that specific table, and visually verify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.Tag'>\n"
     ]
    }
   ],
   "source": [
    "marginaltable = captionedtables[3]\n",
    "print(type(marginaltable))\n",
    "print(marginaltable.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we grab all the rows from the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginalrows = marginaltable.findAll(\"tr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that our data starts at the third row, and note how individual blocks of text are \n",
    "children as well as the table cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', <td bgcolor=\"#fff0f0\">151205</td>, '\\n', <td>2015-12-05 19:55:25</td>, '\\n', <td>2019-10-11</td>, '\\n', <td><span class=\"nowrap\"><span data-sort-value=\"7003300000000000000♠\"></span>3000<span style=\"margin-left:0.3em;\"><span style=\"display:inline-block;margin-bottom:-0.3em;vertical-align:-0.4em;line-height:1.2em;font-size:85%;text-align:right;\">+2400<br/>−1600</span></span></span></td>, '\\n', <td>H,L</td>, '\\n', <td>0.61</td>, '\\n', <td><span class=\"nowrap\"><span data-sort-value=\"6999140000000000000♠\"></span>0.14<span style=\"margin-left:0.3em;\"><span style=\"display:inline-block;margin-bottom:-0.3em;vertical-align:-0.4em;line-height:1.2em;font-size:85%;text-align:right;\">+0.40<br/>−0.38</span></span></span></td>, '\\n', <td bgcolor=\"888888\"><div class=\"center\" style=\"width:auto; margin-left:auto; margin-right:auto;\"><span style=\"color:white;\">BH</span></div></td>, '\\n', <td><span class=\"nowrap\"><span data-sort-value=\"7001670000000000000♠\"></span>67<span style=\"margin-left:0.3em;\"><span style=\"display:inline-block;margin-bottom:-0.3em;vertical-align:-0.4em;line-height:1.2em;font-size:85%;text-align:right;\">+28<br/>−17</span></span></span></td>, '\\n', <td bgcolor=\"888888\"><div class=\"center\" style=\"width:auto; margin-left:auto; margin-right:auto;\"><span style=\"color:white;\">BH</span></div></td>, '\\n', <td><span class=\"nowrap\"><span data-sort-value=\"7001420000000000000♠\"></span>42<span style=\"margin-left:0.3em;\"><span style=\"display:inline-block;margin-bottom:-0.3em;vertical-align:-0.4em;line-height:1.2em;font-size:85%;text-align:right;\">+16<br/>−19</span></span></span></td>, '\\n', <td bgcolor=\"#bbbbbb\">0.47</td>, '\\n', <td></td>, '\\n', <td><sup class=\"reference\" id=\"cite_ref-Nitz2020_73-0\"><a href=\"#cite_note-Nitz2020-73\"><span class=\"cite-bracket\">[</span>60<span class=\"cite-bracket\">]</span></a></sup>\n",
      "</td>]\n"
     ]
    }
   ],
   "source": [
    "print(marginalrows[2].contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build a list of records, where each record is a dictionary. The keys are the column\n",
    "names, and the values are the column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordset = [ { \"event\": r.contents[1].string, \"at\": r.contents[3].string } for r in marginalrows[2:] ]\n",
    "print(recordset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally this list of records can be directly converted to Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "marginaldf = pd.DataFrame.from_records(recordset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
