{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process HURDAT\n",
    "\n",
    "In this notebook we will process the HURDAT text files to produce a single combined `*.csv`.\n",
    "The notebook will demonstrate the following Python concepts:\n",
    "\n",
    "* Context managers\n",
    "* Reading a file line by line.\n",
    "* Writing a file line by line.\n",
    "* Splitting strings by position.\n",
    "* Cleaning and coercing strings.\n",
    "* Unit testing.\n",
    "* I/O buffer optimizations.\n",
    "* Simple text progress indicators.\n",
    "\n",
    "The source data and documentation can be found on the\n",
    "[NOAA website](https://www.aoml.noaa.gov/hrd/hurdat/Data_Storm.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify the Type of Row\n",
    "\n",
    "The text files contain two different types of rows:\n",
    "\n",
    "* A header row that identifies storm of the subsequent track records.\n",
    "* The storm track data.\n",
    "\n",
    "Identifying which type of row we are working with is an excellent use of\n",
    "[regular expressions](https://docs.python.org/3/library/re.html). The\n",
    "[how-to guide](https://docs.python.org/3/howto/regex.html) regular expressions in Python is\n",
    "helpful. We can start by looking at an example of each type and reading the documentation in\n",
    "the `*.pdf` file. We can use [RegEx101](https://regex101.com/) for rapid interactive testing\n",
    "of our regular expressions.\n",
    "\n",
    "The most common Canadian Regular Expression matches the postal code:\n",
    "```regex\n",
    "[a-z][0-9][a-z][0-9][a-z][0-9]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<regex.Match object; span=(0, 38), match='EP052002,            DOUGLAS,     27,\\n'>\n",
      "None\n",
      "None\n",
      "None\n",
      "<regex.Match object; span=(0, 126), match='19800813, 0600,  , TD, 15.2N,  22.5W,  25, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\\n'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "ISHEADER = re.compile(\"^[^,]{8},[^,]{19},[^,]{7},\\n$\")\n",
    "ISTRACK = re.compile(\"^[^,]{8},[^,]{5},[^,]{2},[^,]{3},[^,]{6},[^,]{7},[^,]{4}(,[^,]{5}){14}\\n$\")\n",
    "testheader = \"EP052002,            DOUGLAS,     27,\\n\"\n",
    "testtrack = \"19800813, 0600,  , TD, 15.2N,  22.5W,  25, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999, -999\\n\"\n",
    "testfail = \"Hello World\\n\"\n",
    "print(ISHEADER.fullmatch(testheader))\n",
    "print(ISHEADER.fullmatch(testtrack))\n",
    "print(ISHEADER.fullmatch(testfail))\n",
    "print(ISTRACK.fullmatch(testheader))\n",
    "print(ISTRACK.fullmatch(testtrack))\n",
    "print(ISTRACK.fullmatch(testfail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulate the Identification\n",
    "\n",
    "We take the working logic and put it in a function that we can cleanly reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isheader(line):\n",
    "    \"\"\"\n",
    "    Determine the type of row and return an indicator of the row type:\n",
    "    * True if header.\n",
    "    * False if track.\n",
    "    * None if no match found.\n",
    "    \"\"\"\n",
    "    ISHEADER = re.compile(r\"^[^,]{8},[^,]{19},[^,]{7},\\n$\")\n",
    "    ISTRACK = re.compile(r\"^[^,]{8},[^,]{5},[^,]{2},[^,]{3},[^,]{6},[^,]{7},[^,]{4}(,[^,]{5}){14}\\n$\")\n",
    "    if ISHEADER.fullmatch(line) is not None:\n",
    "        return True\n",
    "    elif ISTRACK.fullmatch(line) is not None:\n",
    "        return False\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Test the Function\n",
    "\n",
    "Using the tests from before we can make sure the function works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(isheader(testheader))\n",
    "print(isheader(testtrack))\n",
    "print(isheader(testfail))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulate Header Parsing\n",
    "\n",
    "This function will extract and coerce the elements of the header:\n",
    "\n",
    "* Unique identifier in database\n",
    "* Year of season\n",
    "* Storm number in season\n",
    "* Basin Name\n",
    "* Storm Name\n",
    "* Tracks\n",
    "\n",
    "To clean the parsed strings we remove the left hand spaces or zeros using `lstrip()` and\n",
    "then set any missing data flags to the empty string using `removesuffix()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseheader(line):\n",
    "    \"\"\"\n",
    "    Parse and tidy-up the elements of the header. Returns identification elements of the\n",
    "    storm:\n",
    "    * `identifier` - unique identifier of the storm in the source.\n",
    "    * `basincode` - identifier of the basin.\n",
    "    * `basinname` - decoded name of the basin.\n",
    "    * `stormnumber` - ordinal of storm in the season and basin.\n",
    "    * `seasonyear` - beginning year of the storm season.\n",
    "    * `stormname` - name of storm when available.\n",
    "    * `stormtracks` - number of storm track records in source.\n",
    "    \"\"\"\n",
    "    BASIN = {\n",
    "        \"AL\": \"Atlantic\",\n",
    "        \"EP\": \"East Pacific\",\n",
    "        \"CP\": \"Central Pacific\"\n",
    "    }\n",
    "    identifier = line[0:8]\n",
    "    basincode = \"\"\n",
    "    basinname = \"\"\n",
    "    basincode = line[0:2].lstrip()\n",
    "    basinname = BASIN.get(basincode, \"\")\n",
    "    stormnumber = line[2:4].lstrip(\"0\")\n",
    "    seasonyear = line[4:8]\n",
    "    stormname = line[9:28].lstrip().removesuffix(\"UNNAMED\")\n",
    "    stormtracks = line[29:36].lstrip()\n",
    "   \n",
    "    # Send\n",
    "    return (\n",
    "        identifier,\n",
    "        basincode,\n",
    "        basinname,\n",
    "        stormnumber,\n",
    "        seasonyear,\n",
    "        stormname,\n",
    "        stormtracks\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Header Process\n",
    "\n",
    "Test on your branches or corner cases. In this case put in a test for each element in the\n",
    "`BASIN` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AL011851', 'AL', 'Atlantic', '1', '1851', '', '14')\n",
      "('AL142012', 'AL', 'Atlantic', '14', '2012', 'NADINE', '96')\n",
      "('EP061950', 'EP', 'East Pacific', '6', '1950', '', '9')\n",
      "('CP011990', 'CP', 'Central Pacific', '1', '1990', 'AKA', '32')\n"
     ]
    }
   ],
   "source": [
    "print(parseheader(\"AL011851,            UNNAMED,     14,\"))\n",
    "print(parseheader(\"AL142012,             NADINE,     96,\"))\n",
    "print(parseheader(\"EP061950,            UNNAMED,      9,\"))\n",
    "print(parseheader(\"CP011990,                AKA,     32,\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulate Track Parsing\n",
    "\n",
    "In this case we want the details of the storm track:\n",
    "\n",
    "* Date and time of observation\n",
    "* Type of record\n",
    "* Storm status\n",
    "* Latitude\n",
    "* Longitude\n",
    "* Minimum pressure\n",
    "* Maximum wind\n",
    "* Eye radius\n",
    "* 34kt radius\n",
    "\n",
    "To clean the parsed strings we remove the left hand spaces or zeros using `lstrip()` and\n",
    "then set any missing data flags to the empty string using `removesuffix()`.\n",
    "\n",
    "Latitude is reported in Northings with a suffix `N` for north of the equator and a suffix\n",
    "`S` for south of the equator. To convert this to Decimal all Latitudes south of the equator\n",
    "need a negative sign.\n",
    "\n",
    "Likewise Longitude is reported in Eastings with a suffix `E` for east of the zero meridian\n",
    "`W` for west of the zero meridian. To convert this to decimal all Longitudes to the west of\n",
    "the zero meridian need a negative sign.\n",
    "\n",
    "To accomplish this we will use the \n",
    "[character translation](https://docs.python.org/3/library/stdtypes.html#str.translate)\n",
    "static method of strings, passing a\n",
    "[translation table](https://docs.python.org/3/library/stdtypes.html#str.maketrans)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "<class 'float'>\n",
      "True\n",
      "{78: '', 83: '-', 69: '', 87: '-'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'-0123456789-'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `maketrans` is a static function of strings. You do no need an actual string to call\n",
    "# this method. You just need the general class definition. The `type` function is a built-in\n",
    "# method that tells us the name of the type (or class) of the data.\n",
    "print(type(\"Aaron\") == str)\n",
    "print(type(10.0))\n",
    "print(type(10.0) == float)\n",
    "NORTHINGS = str.maketrans(\n",
    "    {\n",
    "        \"N\": \"\",\n",
    "        \"S\": \"-\",\n",
    "        \"E\": \"\",\n",
    "        \"W\": \"-\"\n",
    "    }\n",
    ")\n",
    "print(NORTHINGS)\n",
    "\"S01234N567E89W\".translate(NORTHINGS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsetrack(line):\n",
    "    \"\"\"\"\n",
    "    Extract and tidy-up individual observation records. Returns the details of the\n",
    "    observations:\n",
    "    * `trackcode` - Code of type of observation.\n",
    "    * `tracktype` - Decoded type of observation.\n",
    "    * `stormcode` - Code of type of storm at observation.\n",
    "    * `stormtype` - Decoded type of storm at observation.\n",
    "    * `latitude` - Latitude in hemisphere.\n",
    "    * `longitude` - Longitude in hemisphere.\n",
    "    * `wind` - Maximum wind speed in kt.\n",
    "    * `pressure` - Minimum pressure in mbar.\n",
    "    * `neradius` - NE corner of furthest extent in nmi.\n",
    "    * `seradius` - SE corner of furthest extent in nmi.\n",
    "    * `swradius` - SW corner of furthest extent in nmi.\n",
    "    * `nwradius` - NW corner of furthest extent in nmi.\n",
    "    * `eyeradius` - Radius of maximum wind speed in nmi.\n",
    "    \"\"\"\n",
    "    TRACK = {\n",
    "        \"C\": \"Closest to Coast\",\n",
    "        \"G\": \"Genesis\", \n",
    "        \"I\": \"Peak Pressure and Wind\",\n",
    "        \"L\": \"Landfall\",\n",
    "        \"P\": \"Minimum Pressure\",\n",
    "        \"R\": \"Intensity Details\",\n",
    "        \"S\": \"Storm Type Change\", \n",
    "        \"T\": \"Position Details\",\n",
    "        \"W\": \"Maximum Wind\" \n",
    "    }\n",
    "    STORM = {\n",
    "        \"TD\": \"Tropical Depression\",\n",
    "        \"TS\": \"Tropical Storm\",\n",
    "        \"HU\": \"Tropical Hurricane\",\n",
    "        \"EX\": \"Extratropical Cyclone\",\n",
    "        \"SD\": \"Subtropical Depression\",\n",
    "        \"SS\": \"Subtropical Storm\",\n",
    "        \"LO\": \"Low Pressure\",\n",
    "        \"WV\": \"Tropical Wave\",\n",
    "        \"DB\": \"Disturbance\",\n",
    "        \"TY\": \"Typhoon\",\n",
    "        \"ST\": \"Subtropical Typhoon\",\n",
    "        \"ET\": \"Extratropical Typhoon\",\n",
    "        \"PT\": \"Extratropical Low\"\n",
    "    }\n",
    "    HEMISPHERE = str.maketrans(\n",
    "        {\n",
    "            \"N\": \"\",\n",
    "            \"S\": \"-\",\n",
    "            \"E\": \"\",\n",
    "            \"W\": \"-\"\n",
    "        }\n",
    "    )\n",
    "    year = line[0:4]\n",
    "    month = line[4:6]\n",
    "    day = line[6:8]\n",
    "    hour = line[10:12]\n",
    "    minute = line[12:14]\n",
    "    trackcode = line[15:17].lstrip()\n",
    "    tracktype = TRACK.get(trackcode, \"\")\n",
    "    stormcode = line[18:21].lstrip()\n",
    "    stormtype = STORM.get(stormcode, \"\")\n",
    "    latitude = line[22:27].lstrip().lstrip(\"-\")\n",
    "    northing = line[27:28].translate(HEMISPHERE)\n",
    "    longitude = line[29:35].lstrip().lstrip(\"-\")\n",
    "    easting = line[35:36].translate(HEMISPHERE)\n",
    "    wind = line[37:41].lstrip().removesuffix(\"-99\")\n",
    "    pressure = line[42:47].lstrip().removesuffix(\"-999\")\n",
    "    neradius = line[48:53].lstrip().removesuffix(\"-999\")\n",
    "    seradius = line[54:59].lstrip().removesuffix(\"-999\")\n",
    "    swradius = line[60:65].lstrip().removesuffix(\"-999\")\n",
    "    nwradius = line[66:71].lstrip().removesuffix(\"-999\")\n",
    "    eyeradius = line[120:125].lstrip().removesuffix(\"-999\")\n",
    "\n",
    "    # Send. Serialize time using JSON ISO standard\n",
    "    return (\n",
    "        f\"{year}-{month}-{day}T{hour}:{minute}Z\",\n",
    "        trackcode,\n",
    "        tracktype,\n",
    "        stormcode,\n",
    "        stormtype,\n",
    "\n",
    "        # To Do: Format Northing/Southing\n",
    "        f\"{northing}{latitude}\",\n",
    "\n",
    "        # To Do: Format Easting/Westing\n",
    "        f\"{easting}{longitude}\",\n",
    "\n",
    "        wind,\n",
    "        pressure,\n",
    "        neradius,\n",
    "        seradius,\n",
    "        swradius,\n",
    "        nwradius,\n",
    "        eyeradius\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Track Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2014-08-08T12:30Z', 'L', 'Landfall', 'TS', 'Tropical Storm', '19.2', '-155.4', '50', '1001', '100', '60', '0', '90', '')\n",
      "('2023-08-31T18:00Z', '', '', 'TD', 'Tropical Depression', '17.0', '-27.0', '30', '1006', '0', '0', '0', '0', '50')\n",
      "('2023-09-01T06:00Z', '', '', 'TS', 'Tropical Storm', '32.9', '-52.4', '55', '996', '30', '30', '20', '20', '10')\n",
      "('2015-07-13T06:00Z', '', '', 'TS', 'Tropical Storm', '13.7', '178.5', '55', '982', '50', '30', '30', '45', '')\n"
     ]
    }
   ],
   "source": [
    "print(parsetrack(\"20140808, 1230, L, TS, 19.2N, 155.4W,  50, 1001,  100,   60,    0,   90,   40,    0,    0,   20,    0,    0,    0,    0, -999\"))\n",
    "print(parsetrack(\"20230831, 1800,  , TD, 17.0N,  27.0W,  30, 1006,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   50\"))\n",
    "print(parsetrack(\"20230901, 0600,  , TS, 32.9N,  52.4W,  55,  996,   30,   30,   20,   20,   20,   20,    0,    0,    0,    0,    0,    0,   10\"))\n",
    "print(parsetrack(\"20150713, 0600,  , TS, 13.7N, 178.5E,  55,  982,   50,   30,   30,   45,   30,    0,    0,   30,    0,    0,    0,    0, -999\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encapsulate Processing\n",
    "\n",
    "We guard the file processing in a function so that all the resources are released cleanly\n",
    "when we are done processing.\n",
    "\n",
    "To provide a progress prompt we are going to use the `end` named argument of the `print`\n",
    "command and specify that the end is a carriage return `\\r` (back to beginning of same line).\n",
    "```python\n",
    "print(f\"Processed: {counter}\", end = \"\\r\")\n",
    "```\n",
    "\n",
    "We need to accomplish the following, for each file:\n",
    "\n",
    "1. Distinguish between headers and tracks.\n",
    "2. If it is a storm header, save the values for use on the storm track records.\n",
    "3. If it is a storm track extract the values\n",
    "4. Write the storm header and storm track to an output file as a new line\n",
    "5. Close everything\n",
    "\n",
    "As well we will create progress counters to report the data processing progress.\n",
    "\n",
    "**!Python line iterators in for loops include the newline character `\\n`!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/hurdat2-atl.txt\n",
      "../data/hurdat2-nepac.txt\n"
     ]
    }
   ],
   "source": [
    "# Our program will process each file identically, so we put the processing in a loop\n",
    "# that loops through each file.\n",
    "SOURCES = [\n",
    "    \"../data/hurdat2-atl.txt\",\n",
    "    \"../data/hurdat2-nepac.txt\"\n",
    "]\n",
    "for source in SOURCES:\n",
    "    print(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processhurdat():\n",
    "    \"\"\"\n",
    "    Process both HURDAT2 files into a single file `hurdat2.csv`. Initially all options are\n",
    "    hardcoded. We can change these to arguments later.\n",
    "    \"\"\"\n",
    "\n",
    "    # Note that we are using the UNIX/LINUX file separator `/`, if you use the Windows\n",
    "    # make sure to use the double `\\\\` to prevent escape sequence mistakes.\n",
    "    SOURCES = [\n",
    "        \"../data/hurdat2-atl.txt\",\n",
    "        \"../data/hurdat2-nepac.txt\"\n",
    "    ]\n",
    "    TARGET = \"../data/hurdat2.csv\"\n",
    "    COLUMNS = (\n",
    "        \"\\\"Identifier\\\",\" +\n",
    "        \"\\\"Basin Code\\\",\" +\n",
    "        \"\\\"Basin Name\\\",\" +\n",
    "        \"\\\"Storm Number\\\",\" +\n",
    "        \"\\\"Season Year\\\",\" +\n",
    "        \"\\\"Storm Name\\\",\" +\n",
    "        \"\\\"Tracks\\\",\" +\n",
    "        \"\\\"Observed\\\",\" +\n",
    "        \"\\\"Track Code\\\",\" +\n",
    "        \"\\\"Track Type\\\",\" +\n",
    "        \"\\\"Storm Code\\\",\" +\n",
    "        \"\\\"Storm Type\\\",\" +\n",
    "        \"\\\"Latitude\\\",\" +\n",
    "        \"\\\"Longitude\\\",\" +\n",
    "        \"\\\"Maximum Wind (kt)\\\",\" +\n",
    "        \"\\\"Minimum Pressure (mbar)\\\",\" +\n",
    "        \"\\\"NE Radius (nmi)\\\",\" +\n",
    "        \"\\\"SE Radius (nmi)\\\",\" +\n",
    "        \"\\\"SW Radius (nmi)\\\",\" +\n",
    "        \"\\\"NW Radius (nmi)\\\",\" +\n",
    "        \"\\\"Eye Radius (nmi)\\\"\\n\"\n",
    "    )\n",
    "\n",
    "    # Open the target for writing\n",
    "    with open(TARGET, \"a\") as outfile:\n",
    "        print(f\"Writing: {TARGET}\")\n",
    "        outfile.write(COLUMNS)\n",
    "\n",
    "        # Open each file for reading\n",
    "        for source in SOURCES:\n",
    "            print(f\"Reading: {source}\")\n",
    "\n",
    "            # Reset progress counters\n",
    "            reads = 0\n",
    "            storms = 0\n",
    "            tracks = 0\n",
    "            filestart = time.time_ns()\n",
    "        \n",
    "            # Loop through each record\n",
    "            with open(source, \"r\") as infile:\n",
    "                for line in infile:\n",
    "\n",
    "                    # reads = 1 + reads is the same as below\n",
    "                    reads += 1\n",
    "\n",
    "                    # What type of line is it\n",
    "                    foundheader = isheader(line)\n",
    "\n",
    "                    # Store the storm identifiers of a header. Mirror explicit check.\n",
    "                    if foundheader is True:\n",
    "                        storms += 1\n",
    "                        (\n",
    "                            identifier,\n",
    "                            basincode,\n",
    "                            basinname,\n",
    "                            stormnumber,\n",
    "                            seasonyear,\n",
    "                            stormname,\n",
    "                            stormtracks\n",
    "                        ) = parseheader(line)\n",
    "\n",
    "                    # Write a storm track. Use explicit Boolean check to avoid Falsy.\n",
    "                    elif foundheader is False:\n",
    "                        tracks += 1\n",
    "                        (\n",
    "                            observed,\n",
    "                            trackcode,\n",
    "                            tracktype,\n",
    "                            stormcode,\n",
    "                            stormtype,\n",
    "                            latitude,\n",
    "                            longitude,\n",
    "                            wind,\n",
    "                            pressure,\n",
    "                            neradius,\n",
    "                            seradius,\n",
    "                            swradius,\n",
    "                            nwradius,\n",
    "                            eyeradius\n",
    "                        ) = parsetrack(line)\n",
    "                        outfile.write(\n",
    "                            f\"\\\"{identifier}\\\",\" +\n",
    "                            f\"\\\"{basincode}\\\",\" +\n",
    "                            f\"\\\"{basinname}\\\",\" +\n",
    "                            f\"\\\"{stormnumber}\\\",\" +\n",
    "                            f\"\\\"{seasonyear}\\\",\" +\n",
    "                            f\"\\\"{stormname}\\\",\" +\n",
    "                            f\"\\\"{stormtracks}\\\",\" +\n",
    "                            f\"\\\"{observed}\\\",\" +\n",
    "                            f\"\\\"{trackcode}\\\",\" +\n",
    "                            f\"\\\"{tracktype}\\\",\" +\n",
    "                            f\"\\\"{stormcode}\\\",\" +\n",
    "                            f\"\\\"{stormtype}\\\",\" +\n",
    "                            f\"\\\"{latitude}\\\",\" +\n",
    "                            f\"\\\"{longitude}\\\",\" +\n",
    "                            f\"\\\"{wind}\\\",\" +\n",
    "                            f\"\\\"{pressure}\\\",\" +\n",
    "                            f\"\\\"{neradius}\\\",\" +\n",
    "                            f\"\\\"{seradius}\\\",\" +\n",
    "                            f\"\\\"{swradius}\\\",\" +\n",
    "                            f\"\\\"{nwradius}\\\",\" +\n",
    "                            f\"\\\"{eyeradius}\\\"\\n\"\n",
    "                        )\n",
    "\n",
    "                    # Update progress every 1000 reads\n",
    "                    if reads % 10000 == 1:\n",
    "                        print(\n",
    "                            f\"Reads {reads} = Storms {storms} + Tacks {tracks}\",\n",
    "                            end = \"\\r\",\n",
    "                            flush = True\n",
    "                        )\n",
    "            print(\n",
    "                f\"Reads {reads} = Storms {storms} + Tacks {tracks}\",\n",
    "                end = \"\\r\",\n",
    "                flush = True\n",
    "            )\n",
    "            fileend = time.time_ns()\n",
    "            fileduration = (fileend - filestart) / 1000000000\n",
    "            readrate = (fileend - filestart) / (1000 * reads)\n",
    "            print()\n",
    "            print(f\"{fileduration:.3f}(s) {readrate:.3f}(\\u03BCs/r)\")\n",
    "\n",
    "    # Send\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Processing\n",
    "\n",
    "We can quickly test our progress so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing: ../data/hurdat2.csv\n",
      "Reading: ../data/hurdat2-atl.txt\n",
      "Reads 56722 = Storms 1973 + Tacks 54748\n",
      "2.162(s) 38.118(μs/r)\n",
      "Reading: ../data/hurdat2-nepac.txt\n",
      "Reads 32407 = Storms 1227 + Tacks 31179\n",
      "1.269(s) 39.170(μs/r)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "processhurdat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizations\n",
    "\n",
    "There are three optimizations we can do to speed up the processing:\n",
    "\n",
    "1. Batch the terminal updates into groups of 1000 to 10000.\n",
    "2. Move the constants out of the functions. Currently the constants are re-allocated on\n",
    "every function call. We can move them out of the function and either pass them in as an\n",
    "argument to the function, or bind with `nonlocal`.\n",
    "3. Move the inner code of the `for` loop into its own locally defined function.\n",
    "\n",
    "According to the Python documentation line-by-line file reading is already an optimized\n",
    "stream, and [writing](https://docs.python.org/3/library/io.html#io.RawIOBase.write) is\n",
    "buffered at the OS level.\n",
    "\n",
    "We can time our code to the nanosecond in Python by reading the\n",
    "[processor clock time](https://docs.python.org/3/library/time.html#time.time_ns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python allows multiple ways of writing string literals with either single or double quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '\"\"'\n",
    "b = \"\\\"\\\"\"\n",
    "print(a)\n",
    "print(b)\n",
    "print(a == b)\n",
    "print(False is not None)\n",
    "print(None is False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency Injection and Cancellation Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factory():\n",
    "    \"\"\"\n",
    "    Creates the engine and protects the scope of the state of the engine between repeated\n",
    "    calls of the engine.\n",
    "    \"\"\"\n",
    "    state = False\n",
    "    def engine():\n",
    "        \"\"\"\n",
    "        Updates the state and returns whether to continue.\n",
    "        \"\"\"\n",
    "        nonlocal state\n",
    "        return state\n",
    "    return engine\n",
    "def executor(engine):\n",
    "    \"\"\"\n",
    "    Runs the engine and cancels the execution\n",
    "    \"\"\"\n",
    "    def proceed():\n",
    "        \"\"\"\n",
    "        Sets the conditions to cancel execution\n",
    "        \"\"\"\n",
    "        return False\n",
    "    while proceed() and engine():\n",
    "        pass\n",
    "\n",
    "# The factory produces an engine that the executor repeatedly calls.\n",
    "executor(factory())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
